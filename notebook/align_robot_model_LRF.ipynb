{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align robot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show pointclouds\n",
    "import open3d as o3d\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "from os.path import join, abspath, dirname\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcdCamera(scale=1.0, color=[1, 0, 0]):\n",
    "    points = [[-1, 0.75, 0],[1, 0.75, 0],[1, -0.75, 0],[-1, -0.75, 0],[0,0,-0.6]]\n",
    "    lines = [[0,1],[1,2],[2,3],[3,0],\n",
    "             [0,4],[1,4],[2,4],[3,4]]\n",
    "    colors = [color for i in range(len(lines))]\n",
    "    line_set = o3d.geometry.LineSet()\n",
    "\n",
    "    points = np.array(points)*scale\n",
    "    line_set.points = o3d.utility.Vector3dVector(points)\n",
    "    line_set.lines = o3d.utility.Vector2iVector(lines)\n",
    "    line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "    return line_set\n",
    "\n",
    "def axis(scale=1.0):\n",
    "    points = [[0,0,0],[1,0,0],[0,1,0],[0,0,1]]\n",
    "    lines = [[0, i] for i in range(1,4)]\n",
    "    colors = [[i==0,i==1,i==2] for i in range(len(lines))]\n",
    "    line_set = o3d.geometry.LineSet()\n",
    "\n",
    "    points = np.array(points)*scale\n",
    "    line_set.points = o3d.utility.Vector3dVector(points)\n",
    "    line_set.lines = o3d.utility.Vector2iVector(lines)\n",
    "    line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "    return line_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load camera poses and robot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAM_NUM = 4\n",
    "\n",
    "FOLDER = '../data'\n",
    "robot_file = join(FOLDER, 'robot.ply')\n",
    "print(\"robot file:\", robot_file)\n",
    "\n",
    "fs_read = cv2.FileStorage(join(FOLDER, 'final_camera_poses.yml'), cv2.FILE_STORAGE_READ)\n",
    "T = {}\n",
    "for key in fs_read.root().keys():\n",
    "    print(\"camera pose:\", key)\n",
    "    T[key] = fs_read.getNode(key).mat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize robot model and camera poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_pcd = o3d.io.read_point_cloud(robot_file)\n",
    "o3d.visualization.draw_geometries([robot_pcd.voxel_down_sample(voxel_size=0.005), axis(0.5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show images for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_pcds = []\n",
    "for i in range(CAM_NUM):\n",
    "    cam_pcd = pcdCamera(0.1, color=[i==0,i==1,i==2])\n",
    "    key = f\"originimg{i}\"\n",
    "    cam_pcd.transform(T[key])\n",
    "    cam_pcds.append(cam_pcd)\n",
    "show_pcds = [*cam_pcds, axis(0.5)]\n",
    "o3d.visualization.draw_geometries(show_pcds, width=1200, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for i in range(CAM_NUM):\n",
    "    fname = join(FOLDER, f'img{i}.jpg')\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    imgs.append(img)\n",
    "    \n",
    "fig, ax = plt.subplots(1, CAM_NUM, figsize=(12,4))\n",
    "for i, (img, a) in enumerate(zip(imgs, ax)):\n",
    "    a.imshow(img)\n",
    "    a.set_yticklabels([])\n",
    "    a.set_title(f\"img{i}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Click points on robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_points(pcd):\n",
    "    print(\"\")\n",
    "    print(\"1) Please pick at point using [shift + left click]\")\n",
    "    print(\"   Press [shift + right click] to undo point picking\")\n",
    "    print(\"2) Afther picking points, press q for close the window\")\n",
    "    vis = o3d.visualization.VisualizerWithEditing()\n",
    "    vis.create_window(width=1200, height=800)\n",
    "    vis.add_geometry(pcd)\n",
    "    vis.run()  # user picks points\n",
    "    vis.destroy_window()\n",
    "    print(\"\")\n",
    "    return vis.get_picked_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'click at {CAM_NUM} cameras')\n",
    "picked_id = pick_points(robot_pcd)\n",
    "print(picked_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align by Umeyama's method\n",
    "S. Umeyama, \"Least-squares estimation of transformation parameters between two point patterns,\" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 13, no. 4, pp. 376-380, April 1991.\n",
    "doi: 10.1109/34.88573  \n",
    "https://ieeexplore.ieee.org/document/88573\n",
    "\n",
    "Reference for implementation  \n",
    "https://github.com/MichaelGrupp/evo/blob/5fce036136001c0ee7cb2d03e992bef9c5abe746/evo/core/geometry.py#L30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min ||pt_to - T*pt_from||^2\n",
    "def align_pts(pt_from, pt_to, with_scale=True):\n",
    "    x = pt_from.copy().T\n",
    "    y = pt_to.copy().T\n",
    "    assert x.shape == y.shape\n",
    "\n",
    "    # m dim, n points\n",
    "    m, n = x.shape\n",
    "    mean_x = x.mean(axis=1)[:,np.newaxis]\n",
    "    mean_y = y.mean(axis=1)[:,np.newaxis]\n",
    "\n",
    "    # zero center\n",
    "    x -= mean_x\n",
    "    y -= mean_x\n",
    "    sigma_x = np.mean(np.linalg.norm(x, axis=0)**2)\n",
    "    \n",
    "    # \n",
    "    cov_xy = np.zeros((m, m))\n",
    "    for i in range(n):\n",
    "        cov_xy += np.outer(y[:,i], x[:,i])\n",
    "    cov_xy = cov_xy*1.0/n\n",
    "    \n",
    "    # svd\n",
    "    u, d, v = np.linalg.svd(cov_xy)\n",
    "\n",
    "    s = np.eye(m)\n",
    "    if np.linalg.det(u) * np.linalg.det(v) < 0.0:\n",
    "        s[m - 1, m - 1] = -1\n",
    "\n",
    "    R = u.dot(s).dot(v)\n",
    "    c = 1 / sigma_x * np.trace(np.diag(d).dot(s)) if with_scale else 1.0\n",
    "    c = float(c)\n",
    "    t = mean_y - c*R.dot(mean_x)\n",
    "    t = t.flatten()\n",
    "    return c, R, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# picked_id = [23660, 0, 30012, 40612]\n",
    "robot_pcd = o3d.io.read_point_cloud(robot_file)\n",
    "picked_pts = np.array(robot_pcd.points)[picked_id] # copy points\n",
    "\n",
    "cam_pts = []\n",
    "for i in range(CAM_NUM):\n",
    "    key = f\"originimg{i}\"\n",
    "    cam_pts.append(T[key][:3,3])\n",
    "cam_pts = np.array(cam_pts)\n",
    "\n",
    "# estimate matrix for alignment\n",
    "c, R, t = align_pts(picked_pts, cam_pts)\n",
    "\n",
    "# save pose\n",
    "yml_file = join(FOLDER, \"robot_align_matrix.yml\")\n",
    "fs = cv2.FileStorage(join(FOLDER, yml_file), cv2.FILE_STORAGE_WRITE)\n",
    "fs.write(\"robot_scale\", c)\n",
    "fs.write(\"robot_rvec\", cv2.Rodrigues(R)[0])\n",
    "fs.write(\"robot_tvec\", t)\n",
    "fs.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize aligned pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_pcds = []\n",
    "for i in range(CAM_NUM):\n",
    "    cam_pcd = pcdCamera(0.1, color=[i==0,i==1,i==2])\n",
    "    key = f\"originimg{i}\"\n",
    "    cam_pcd.transform(T[key])\n",
    "    cam_pcds.append(cam_pcd)\n",
    "\n",
    "    \n",
    "robot_pcd = o3d.io.read_point_cloud(robot_file)\n",
    "T_wr = np.eye(4)\n",
    "T_wr[:3,:3] = c*R\n",
    "T_wr[:3,3] = t\n",
    "robot_pcd.transform(T_wr)\n",
    "    \n",
    "show_pcds = [*cam_pcds, robot_pcd, axis(0.5)]\n",
    "\n",
    "for it in show_pcds:\n",
    "    it.transform([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "o3d.visualization.draw_geometries(show_pcds, width=1200, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align LRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bev = cv2.imread(join(FOLDER, 'bev.jpg'))\n",
    "data_xy = np.loadtxt(join(FOLDER, 'urg_xy.csv'), delimiter=\",\")\n",
    "\n",
    "fs = cv2.FileStorage(join(FOLDER, 'bev_info.yml'), cv2.FileStorage_READ)\n",
    "pixel_to_m = fs.getNode('pixel_to_m').real()\n",
    "# np.savetxt(join(FOLDER, 'urg_xy_.csv'), data_xy, delimiter=\",\", fmt='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(12,4))\n",
    "ax[0].plot(data_xy[:,0], data_xy[:,1], 'cd')\n",
    "ax[0].set_aspect(aspect=1)\n",
    "\n",
    "ax[1].imshow(bev[:,:,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Click points in LRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRFpcd(data_xy):\n",
    "    num_pts = data_xy.shape[0]\n",
    "    data_z = np.zeros((num_pts))\n",
    "    xyz = np.stack([data_xy[:,0],data_xy[:,1], data_z], axis=1)\n",
    "    lrf_pcd = o3d.geometry.PointCloud()\n",
    "    lrf_pcd.points = o3d.utility.Vector3dVector(xyz)\n",
    "    return lrf_pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 3D point cloud on floor\n",
    "lrf_pcd = LRFpcd(data_xy)\n",
    "o3d.visualization.draw_geometries([lrf_pcd, axis(0.5)], width=1200, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picked_id = pick_points(lrf_pcd)\n",
    "print(picked_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# picked_id = [866, 1021, 204, 416]\n",
    "picked_pts = np.array(lrf_pcd.points)[picked_id] # copy points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Click points in bird's-eye view image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 5\n",
    "pts = []\n",
    "def on_click(event, x, y, flags, param):\n",
    "    global pts\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        pts.append((x, y))\n",
    "        print(f'Added point ({x},{y})')\n",
    "        \n",
    "winname = 'click points'\n",
    "cv2.namedWindow(winname)\n",
    "cv2.setMouseCallback(winname, on_click)\n",
    "while True:\n",
    "    out = bev.copy()\n",
    "    for pt in pts:\n",
    "        cv2.circle(out, pt, r, (0,0,255), 5)\n",
    "\n",
    "    cv2.imshow(winname, out)\n",
    "    key = cv2.waitKey(100)\n",
    "    if key==27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "print('Total number of points:', len(pts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# world_pt.at<double>(0) = (u - uc)*pixel_to_m;\n",
    "# world_pt.at<double>(1) = (-v + vc )*pixel_to_m;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pts = [(135, 180), (134, 271), (348, 374), (347, 259)]\n",
    "\n",
    "# Convert to world coordinate\n",
    "h, w, _ = bev.shape\n",
    "bev_pts = []\n",
    "for pt in pts:\n",
    "    x = (pt[0] - w/2) * pixel_to_m\n",
    "    y = (-pt[1] + h/2) * pixel_to_m    \n",
    "    bev_pts.append([x, y])\n",
    "bev_pts = np.array(bev_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(bev_pts[:,0], bev_pts[:,1], 'cd')\n",
    "plt.plot(picked_pts[:,0], picked_pts[:,1], 'rd')\n",
    "ax.set_aspect(aspect=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picked_pts = picked_pts[:,:2]\n",
    "# estimate matrix for alignment\n",
    "c, R, t = align_pts(picked_pts, bev_pts, False)\n",
    "\n",
    "print(c)\n",
    "print(R)\n",
    "print(t)\n",
    "\n",
    "# save\n",
    "yml_file = join(FOLDER, \"lrf_align_matrix.yml\")\n",
    "fs = cv2.FileStorage(join(FOLDER, yml_file), cv2.FILE_STORAGE_WRITE)\n",
    "fs.write(\"lrf_rot\", np.arctan2(R[1,0], R[0, 0]))\n",
    "fs.write(\"lrf_tvec\", t)\n",
    "fs.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrf_pcd = LRFpcd(data_xy)\n",
    "T = np.eye(4)\n",
    "T[:2,:2] = c*R\n",
    "T[:2,3] = t\n",
    "lrf_pcd.transform(T)\n",
    "    \n",
    "show_pcds = [lrf_pcd, axis(0.5)]\n",
    "show_pcds = [lrf_pcd, axis(0.5), robot_pcd]\n",
    "\n",
    "\n",
    "for it in show_pcds:\n",
    "    it.transform([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "o3d.visualization.draw_geometries(show_pcds, width=1200, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
